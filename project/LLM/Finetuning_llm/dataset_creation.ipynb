{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546fff43",
   "metadata": {},
   "source": [
    "Fine Tuning \n",
    "\n",
    "1. Identify task(s) by prompt-engineering a large LLM\n",
    "\n",
    "2. Find task that you see an LLM doing ~ok at\n",
    "\n",
    "3. Pick one task\n",
    "\n",
    "4. Get ~1000 inputs and outputs for the task (Better than the ~Ok from the LLM)\n",
    "\n",
    "5. Finetune a small LLM on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223bf449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lamini\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# from llama import BasicModelRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b37e1ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/envs/enve/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import datasets                     #hugging face library\n",
    "from datasets import load_dataset       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f982358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 8\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LAMINI_API_KEY\"] = os.getenv(\"LAMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a2fcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/.cache/huggingface/modules/datasets_modules/datasets/c4/584d57ebe81c209b6c7f31727066d2c4b4bba37cb7092cdd83083d5ec11207db/c4.py:53: FutureWarning: Dataset 'c4' is deprecated and will be deleted. Use 'allenai/c4' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pretrained_dataset = load_dataset(\"c4\",\"en\", split=\"train\",streaming=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975da3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Dataset:\n",
      "{'text': 'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.', 'timestamp': '2019-04-25T12:57:54Z', 'url': 'https://klyq.com/beginners-bbq-class-taking-place-in-missoula/'}\n",
      "{'text': 'Discussion in \\'Mac OS X Lion (10.7)\\' started by axboi87, Jan 20, 2012.\\nI\\'ve got a 500gb internal drive and a 240gb SSD.\\nWhen trying to restore using disk utility i\\'m given the error \"Not enough space on disk ____ to restore\"\\nBut I shouldn\\'t have to do that!!!\\nAny ideas or workarounds before resorting to the above?\\nUse Carbon Copy Cloner to copy one drive to the other. I\\'ve done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the clone, the resulting drive won\\'t be bootable. CCC usually works in \"file mode\" and it can easily copy a larger drive (that\\'s mostly empty) onto a smaller drive. If you tell CCC to clone a drive you did NOT boot from, it can work in block copy mode where the destination drive must be the same size or larger than the drive you are cloning from (if I recall).\\nI\\'ve actually done this somehow on Disk Utility several times (booting from a different drive (or even the dvd) so not running disk utility from the drive your cloning) and had it work just fine from larger to smaller bootable clone. Definitely format the drive cloning to first, as bootable Apple etc..\\nThanks for pointing this out. My only experience using DU to go larger to smaller was when I was trying to make a Lion install stick and I was unable to restore InstallESD.dmg to a 4 GB USB stick but of course the reason that wouldn\\'t fit is there was slightly more than 4 GB of data.', 'timestamp': '2019-04-21T10:07:13Z', 'url': 'https://forums.macrumors.com/threads/restore-from-larger-disk-to-smaller-disk.1311329/'}\n",
      "{'text': 'Foil plaid lycra and spandex shortall with metallic slinky insets. Attached metallic elastic belt with O-ring. Headband included. Great hip hop or jazz dance costume. Made in the USA.', 'timestamp': '2019-04-25T10:40:23Z', 'url': 'https://awishcometrue.com/Catalogs/Clearance/Tweens/V1960-Find-A-Way'}\n",
      "{'text': \"How many backlinks per day for new site?\\nDiscussion in 'Black Hat SEO' started by Omoplata, Dec 3, 2010.\\n1) for a newly created site, what's the max # backlinks per day I should do to be safe?\\n2) how long do I have to let my site age before I can start making more blinks?\\nI did about 6000 forum profiles every 24 hours for 10 days for one of my sites which had a brand new domain.\\nThere is three backlinks for every of these forum profile so thats 18 000 backlinks every 24 hours and nothing happened in terms of being penalized or sandboxed. This is now maybe 3 months ago and the site is ranking on first page for a lot of my targeted keywords.\\nbuild more you can in starting but do manual submission and not spammy type means manual + relevant to the post.. then after 1 month you can make a big blast..\\nWow, dude, you built 18k backlinks a day on a brand new site? How quickly did you rank up? What kind of competition/searches did those keywords have?\", 'timestamp': '2019-04-21T12:46:19Z', 'url': 'https://www.blackhatworld.com/seo/how-many-backlinks-per-day-for-new-site.258615/'}\n",
      "{'text': 'The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about what’s included in the mill levy measure.', 'timestamp': '2019-04-20T14:33:21Z', 'url': 'http://bond.dpsk12.org/category/news/'}\n"
     ]
    }
   ],
   "source": [
    "n=5\n",
    "print(\"Pretrained Dataset:\")\n",
    "top_n = itertools.islice(pretrained_dataset,n)\n",
    "for i in top_n:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203a5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"remoanil/lamini-docs-jsonl\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15d30d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "1b65808c-769d-4d5d-98fb-c9efeb88c3d4",
       "rows": [
        [
         "0",
         "What are the different types of documents available in the repository (e.g., installation guide, API documentation, developer's guide)?",
         "Lamini has documentation on Getting Started, Authentication, Question Answer Model, Python Library, Batching, Error Handling, Advanced topics, and class documentation on LLM Engine available at https://lamini-ai.github.io/."
        ],
        [
         "1",
         "What is the recommended way to set up and configure the code repository?",
         "Lamini can be downloaded as a python package and used in any codebase that uses python. Additionally, we provide a language agnostic REST API. We’ve seen users develop and train models in a notebook environment, and then switch over to a REST API to integrate with their production environment."
        ],
        [
         "2",
         "How can I find the specific documentation I need for a particular feature or function?",
         "You can ask this model about documentation, which is trained on our publicly available docs and source code, or you can go to https://lamini-ai.github.io/."
        ],
        [
         "3",
         "Does the documentation include explanations of the code's purpose and how it fits into a larger system?",
         "Our documentation provides both real-world and toy examples of how one might use Lamini in a larger system. In particular, we have a walkthrough of how to build a Question Answer model available here: https://lamini-ai.github.io/example/"
        ],
        [
         "4",
         "Does the documentation provide information about any external dependencies or libraries used by the code?",
         "External dependencies and libraries are all available on the Python package hosting website Pypi at https://pypi.org/project/lamini/"
        ],
        [
         "5",
         "How frequently is the documentation updated to reflect changes in the code?",
         "Documentation on such a fast moving project is difficult to update regularly - that’s why we’ve built this model to continually update users on the status of our product."
        ],
        [
         "6",
         "Is there a community or support channel mentioned in the documentation where I can ask questions or seek help?",
         "You can always reach out to us at support@lamini.ai."
        ],
        [
         "7",
         "Are there any API references or documentation available for the codebase?",
         "All our public documentation is available here https://lamini-ai.github.io/"
        ],
        [
         "8",
         "Is there a troubleshooting guide or a list of common issues and their solutions?",
         "All our public documentation is available here https://lamini-ai.github.io/"
        ],
        [
         "9",
         "Are there any examples or sample code provided in the documentation?",
         "Examples and sample documentation is available at https://lamini-ai.github.io/. In particular, there is a QA example where we show you how to feed your documentation into a model to ask questions about a code base. Additionally, sample code and colab notebooks are provided and linked throughout the documentation where relevant. Feedback on our documentation is greatly appreciated - we care about making LLMs - and by extension Lamini - easier to use. Please direct any feedback to support@lamini.ai."
        ],
        [
         "10",
         "What is a type system?",
         "The Lamini Type system is a code-first data representation library built to help users pipe data into Lamini’s LLM Engine. Lamini Types are simple, built on top of Pydantic BaseModels, and enforce strict typing so that integration into a data pipeline can run seamlessly without any errors."
        ],
        [
         "11",
         "Does the documentation provide a step-by-step tutorial for getting started with the code?",
         "Yes, several walkthroughs are available in the documentation. The documentation also provides links to example Google Colab notebooks which readers might run themselves and can provide a launchpad for iteration on their own data."
        ],
        [
         "12",
         "Do I have to write prompts myself?",
         "No, you only need to represent your data using the Lamini Type system and provide context - natural language description of each field in a Type. Lamini brings the focus of development on the data, bypassing prompt engineering as a step in language model development."
        ],
        [
         "13",
         "How do I add my data to Lamini's interface",
         "You can quickly add data to Lamini’s interface using LLM Engine.add_data. This method allows you to make data available to the model for inference and training."
        ],
        [
         "14",
         "How do I use open model for inference",
         "You can use an open model by specifying the model’s name in the ‘model_name’ parameter in the LLM Engine class initializer."
        ],
        [
         "15",
         "Where do I specify model name",
         "You can specify model_name in both the initialization of LLM Engine or in the function LLM Engine.__call___. In other words, instances of LLM Engine are callable and configurable."
        ],
        [
         "16",
         "What does Context mean?",
         "Context is a natural language description of fields in each of your Types. In other words, context is metadata about your data."
        ],
        [
         "17",
         "Is it compulsory to give context?",
         "Context is only required for certain Type fields: str, int, bool, float, list, set, dict, and tuple. Context is not required for fields which have object types (you don’t need to add context for composed Types)."
        ],
        [
         "18",
         "Is it compulsory to provide input and output types?",
         "Yes, in our python library, the input and output type will be used by the LLM Engine in inference. By providing input and output type, you’re defining a problem statement for the LLM."
        ],
        [
         "19",
         "How should the data be formatted in order to send it to Lamini",
         "You can match the type and metadata to whatever format you’d like."
        ],
        [
         "20",
         "Can I use Lamini as api instead of python library",
         "Yes, we have a REST API available. To see documentation go to https://lamini-ai.github.io/"
        ],
        [
         "21",
         "How do I get api keys?",
         "You can generate an api key in the “API” tab at app.lamini.ai"
        ],
        [
         "22",
         "Do I have to pay for using Lamini?",
         "Everyone starts with 10,000 free credits, which is equivalent to about $100. After that, you can purchase more credits in the “API” tab at app.lamini.ai."
        ],
        [
         "23",
         "Can I fine-tune models on my own data?",
         "Yes! Lamini LLM Engine has fine-tuning support. Contact us for access.  You can also look at the documentation for llm.add_data, which makes your data available to the LLM Engine.  The LLM Engine performs fast training using this data, which should complete in just a few seconds, even for large datasets.  Full fine tuning is more expensive, which is why we ask you to contact us to allocate enough compute resources to support it."
        ],
        [
         "24",
         "Are there any specific guidelines or recommendations on formatting the input data for Lamini?",
         "We suggest you think about language models as advanced problem solvers. Imagine you’re designing a function - what are the inputs and outputs? Lamini LLM Engine can help you build that function - but you’ll need to specify what data you have available and the format of that input data and what you wish the output was. In terms of what specific format the input data is in, Lamini Types are composable and have fields which you can mold to exactly fit your data."
        ],
        [
         "25",
         "Which models does Lamini support?",
         "Lamini supports every OpenAI and Hugging Face model.  For example, gpt3, chat-gpt, gpt4, pythia, gpt-neox, wizard-lm, falcon, etc."
        ],
        [
         "26",
         "Can you fine-tune an openai model?",
         "Yes! Lamini LLM Engine has fine-tuning support, including base models from hugging face as well as OpenAI. Contact us for access.  You can also look at the documentation for llm.add_data, which makes your data available to the LLM Engine.  The LLM Engine performs fast training using this data, which should complete in just a few seconds, even for large datasets.  Full fine tuning is more expensive, which is why we ask you to contact us to allocate enough compute resources to support it."
        ],
        [
         "27",
         "Can I fine-tune GPT 4?",
         "No, GPT-4 doesn't support fine tuning.  However, Lamini does support fine tuning of other base models such as Pythia or other base models available on OpenAI such as GPT-3."
        ],
        [
         "28",
         "Do I need to provide data as train and test split?",
         "No, the LLM Engine internally uses technologies like dev sets to calibrate training.  However, as a best practice in machine learning, we recommend that you develop your own test set that you do not add to the LLM Engine, that allows you to evaluate the performance of the LLM you are building without overfitting.  A gold test set should typically include 10s to 100s of examples that are sufficiently representative of your use case and include high quality labels.  We also recommend using human evaluation to judge the performance of the language model on your test set, instead of metrics like BLEU."
        ],
        [
         "29",
         "I am running into error 500, what should I do?",
         "We have documentation available on how to address common errors here https://lamini-ai.github.io/error_handling/. Lamini’s LLM Engine is under very active development, and we thank you for using us!"
        ],
        [
         "30",
         "Can I use the code documentation as a pillow for a quick nap?",
         "The code documentation is not meant for napping. It is intended to provide information about the code and its functions."
        ],
        [
         "31",
         "Can the documentation predict the winning lottery numbers?",
         "I wish! This documentation only talks about Lamini’s LLM Engine."
        ],
        [
         "32",
         "Is there a hidden message in the documentation that only a master codebreaker can decipher?",
         "There is no hidden message in the documentation. But thank you for reading it!"
        ],
        [
         "33",
         "Can a banana peel really make someone slip and fall?",
         "Let’s keep the discussion relevant to Lamini."
        ],
        [
         "34",
         "Why are pineapples yellow",
         "Let’s keep the discussion relevant to Lamini."
        ],
        [
         "35",
         "Can you sneeze with your eyes open?",
         "Let’s keep the discussion relevant to Lamini."
        ],
        [
         "36",
         "Does the documentation have a secret code that unlocks a hidden treasure?",
         "I wish! This documentation only talks about Lamini’s LLM Engine."
        ],
        [
         "37",
         "Does the documentation have a hidden recipe for the world's best chocolate chip cookies?",
         "I wish! This documentation only talks about Lamini’s LLM Engine."
        ],
        [
         "38",
         "Can I roll up the documentation and use it as a makeshift telescope to spot distant galaxies?",
         "I wish! This documentation only talks about Lamini’s LLM Engine."
        ],
        [
         "39",
         "Can you tickle yourself?",
         "Let’s keep the discussion relevant to Lamini."
        ],
        [
         "40",
         "Are there any step-by-step tutorials or walkthroughs available in the documentation?",
         "Yes, there are step-by-step tutorials and walkthroughs available in the documentation section. Here’s an example for using Lamini to get insights into any python library: https://lamini-ai.github.io/example/"
        ],
        [
         "41",
         "Are there any licensing or copyright details provided in the documentation?",
         "The documentation may include information about the licensing or copyright details of the code, specifying the terms under which it can be used, modified, or distributed."
        ],
        [
         "42",
         "Does the documentation include performance benchmarks or comparisons with other similar solutions?",
         "Currently the documentation does not include performance benchmarks or comparisons with other similar solutions, but seems like a good suggestion, I will let the developers at Lamini know this!!"
        ],
        [
         "43",
         "Does the documentation provide guidelines on handling errors or handling exceptions in the code?",
         "Yes, the documentation provides guidelines for handling errors and exceptions in the code, for more details visit https://lamini-ai.github.io/error_handling/"
        ],
        [
         "44",
         "Can I use the code documentation as a hat to protect myself from rain?",
         "I wish! This documentation only talks about Lamini’s LLM Engine."
        ],
        [
         "45",
         "Can the documentation predict the outcome of a coin toss?",
         "I wish! This documentation only talks about Lamini’s LLM Engine."
        ],
        [
         "46",
         "Can reading the documentation make you instantly fluent in a new language?",
         "The code documentation does not make you fluent in a new language. It is intended to provide information about the code and its functions. You might choose to use the Lamini engine to finetune a multilingual model. Let us know how that goes!"
        ],
        [
         "47",
         "Can you use the documentation as a crystal ball to predict the future?",
         "I wish! This documentation only talks about Lamini’s LLM Engine."
        ],
        [
         "48",
         "Why do cats always land on their feet?",
         "Let’s keep the discussion relevant to Lamini."
        ],
        [
         "49",
         "Can the documentation make you instantly gain six-pack abs?",
         "I wish! This documentation only talks about Lamini’s LLM Engine."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1400
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the different types of documents avai...</td>\n",
       "      <td>Lamini has documentation on Getting Started, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the recommended way to set up and conf...</td>\n",
       "      <td>Lamini can be downloaded as a python package a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I find the specific documentation I ne...</td>\n",
       "      <td>You can ask this model about documentation, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does the documentation include explanations of...</td>\n",
       "      <td>Our documentation provides both real-world and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Does the documentation provide information abo...</td>\n",
       "      <td>External dependencies and libraries are all av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>What is Lamini and what is its collaboration w...</td>\n",
       "      <td>Lamini is a library that simplifies the proces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>How does Lamini simplify the process of access...</td>\n",
       "      <td>Lamini simplifies data access in Databricks by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>What are some of the key features provided by ...</td>\n",
       "      <td>Lamini automatically manages the infrastructur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>How does Lamini ensure data privacy during the...</td>\n",
       "      <td>During the training process, Lamini ensures da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>Can you provide an example use case where Lami...</td>\n",
       "      <td>An example use case where Lamini outperforms C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     What are the different types of documents avai...   \n",
       "1     What is the recommended way to set up and conf...   \n",
       "2     How can I find the specific documentation I ne...   \n",
       "3     Does the documentation include explanations of...   \n",
       "4     Does the documentation provide information abo...   \n",
       "...                                                 ...   \n",
       "1395  What is Lamini and what is its collaboration w...   \n",
       "1396  How does Lamini simplify the process of access...   \n",
       "1397  What are some of the key features provided by ...   \n",
       "1398  How does Lamini ensure data privacy during the...   \n",
       "1399  Can you provide an example use case where Lami...   \n",
       "\n",
       "                                                 answer  \n",
       "0     Lamini has documentation on Getting Started, A...  \n",
       "1     Lamini can be downloaded as a python package a...  \n",
       "2     You can ask this model about documentation, wh...  \n",
       "3     Our documentation provides both real-world and...  \n",
       "4     External dependencies and libraries are all av...  \n",
       "...                                                 ...  \n",
       "1395  Lamini is a library that simplifies the proces...  \n",
       "1396  Lamini simplifies data access in Databricks by...  \n",
       "1397  Lamini automatically manages the infrastructur...  \n",
       "1398  During the training process, Lamini ensures da...  \n",
       "1399  An example use case where Lamini outperforms C...  \n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filename = \"lamini_docs.jsonl\"\n",
    "instruction_dataset_df = pd.read_json(\"/Users/apple/Desktop/project/LLM/Finetuning_llm/Data/lamini_docs.jsonl\", lines=True)\n",
    "instruction_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57adc7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What are the different types of documents available in the repository (e.g., installation guide, API documentation, developer's guide)?Lamini has documentation on Getting Started, Authentication, Question Answer Model, Python Library, Batching, Error Handling, Advanced topics, and class documentation on LLM Engine available at https://lamini-ai.github.io/.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = instruction_dataset_df.to_dict()\n",
    "text = examples[\"question\"][0]+examples['answer'][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aed31548",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"question\" in examples and \"answer\" in examples:\n",
    "    text = examples[\"question\"][0] + examples['answer'][0]\n",
    "elif \"instruction\" in examples and \"response\" in examples:\n",
    "    text = examples[\"instructions\"][0] + examples['response'][0]\n",
    "elif \"input\" in examples and \"output\" in examples:\n",
    "    text = examples[\"input\"][0] + examples['output'][0] \n",
    "else:\n",
    "    text = examples[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa34da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_qa = \"\"\"### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "{answer}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60cb396f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### Question:\\nWhat are the different types of documents available in the repository (e.g., installation guide, API documentation, developer's guide)?\\n\\n### Answer:\\nLamini has documentation on Getting Started, Authentication, Question Answer Model, Python Library, Batching, Error Handling, Advanced topics, and class documentation on LLM Engine available at https://lamini-ai.github.io/.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = examples[\"question\"][0]\n",
    "answer = examples[\"answer\"][0]\n",
    "\n",
    "text_with_prompt_template = prompt_template_qa.format(question=question, answer=answer)\n",
    "text_with_prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c6dc5",
   "metadata": {},
   "source": [
    "here we can see we are using question answering prompt template.\n",
    "\n",
    "we will make input and output seperate because it helps dataset easily for evaluation and for you to know when you will split the data set into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11e99205",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_q = \"\"\"### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b09eb00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = len(examples[\"question\"])\n",
    "finetuning_dataset_text_only=[]\n",
    "finetuning_dataset_question_answer = []\n",
    "for i in range(num_examples):\n",
    "    question = examples[\"question\"][i]\n",
    "    answer = examples[\"answer\"][i]\n",
    "    \n",
    "    text_with_prompt_template_qa = prompt_template_qa.format(question=question,answer=answer)\n",
    "    finetuning_dataset_text_only.append({\"text\":text_with_prompt_template_qa})\n",
    "    \n",
    "    text_with_prompt_template_q = prompt_template_q.format(question=question)\n",
    "    finetuning_dataset_question_answer.append({\"question\":text_with_prompt_template_q, \"answer\": answer})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b701bce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '### Question:\\n'\n",
      "         'What are the different types of documents available in the '\n",
      "         \"repository (e.g., installation guide, API documentation, developer's \"\n",
      "         'guide)?\\n'\n",
      "         '\\n'\n",
      "         '### Answer:\\n'\n",
      "         'Lamini has documentation on Getting Started, Authentication, '\n",
      "         'Question Answer Model, Python Library, Batching, Error Handling, '\n",
      "         'Advanced topics, and class documentation on LLM Engine available at '\n",
      "         'https://lamini-ai.github.io/.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(finetuning_dataset_text_only[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0a8432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Lamini has documentation on Getting Started, Authentication, '\n",
      "           'Question Answer Model, Python Library, Batching, Error Handling, '\n",
      "           'Advanced topics, and class documentation on LLM Engine available '\n",
      "           'at https://lamini-ai.github.io/.',\n",
      " 'question': '### Question:\\n'\n",
      "             'What are the different types of documents available in the '\n",
      "             'repository (e.g., installation guide, API documentation, '\n",
      "             \"developer's guide)?\\n\"\n",
      "             '\\n'\n",
      "             '### Answer:'}\n"
     ]
    }
   ],
   "source": [
    "pprint(finetuning_dataset_question_answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc81cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#abc.jsonl file means each line in abc file is json object.\n",
    "\n",
    "with jsonlines.open(f\"lamini_docs_processed.jsonl\",'w') as writer:\n",
    "    writer.write_all(finetuning_dataset_question_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a21f8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a file to specific folder\n",
    "# with jsonlines.open(os.path.join(\"/Users/apple/Desktop/project/LLM/Finetuning_llm/Data\",f\"lamini_docs_processed.jsonl\"),'w') as writer:\n",
    "#     writer.write_all(finetuning_dataset_question_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de79081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 1260/1260 [00:00<00:00, 85324.41 examples/s]\n",
      "Generating test split: 100%|██████████| 140/140 [00:00<00:00, 34373.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1260\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 140\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#upload dataset to hugging face\n",
    "finetuning_dataset_name = \"lamini/lamini_docs\"\n",
    "finetuning_dataset = load_dataset(finetuning_dataset_name)\n",
    "print(finetuning_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bcc1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
